{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PosgradoMNA/actividades-de-aprendizaje-jeesperon/blob/main/assignment01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOR2vAB-M19Y"
      },
      "source": [
        "# ***Module 2 - Data Wrangling ***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 id=\"data_acquisition\">Data Acquisition</h1>\n",
        "<p>\n",
        "There are various formats for a dataset: .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.<br>\n",
        "\n",
        "In this section, you will learn how to load a dataset into our Jupyter Notebook.<br>\n",
        "\n",
        "In our case, the Automobile Dataset is an online source, and it is in a CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n",
        "\n",
        "<ul>\n",
        "    <li>Data source: <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data</a></li>\n",
        "    <li>Data type: csv</li>\n",
        "</ul>\n",
        "The Pandas Library is a useful tool that enables us to read various datasets into a dataframe; our Jupyter notebook platforms have a built-in <b>Pandas Library</b> so that all we need to do is import Pandas without installing.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "you are running the lab in your  browser, so we will install the libraries using `piplite`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#you are running the lab in your  browser, so we will install the libraries using ``piplite``\n",
        "import piplite\n",
        "import micropip\n",
        "await piplite.install(['pandas'])\n",
        "await piplite.install(['matplotlib'])\n",
        "await piplite.install(['scipy'])\n",
        "await piplite.install(['seaborn'])\n",
        "await micropip.install(['ipywidgets'],keep_going=True)\n",
        "await micropip.install(['tqdm'],keep_going=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#install specific version of libraries used in  lab\n",
        "#! mamba install pandas==1.3.3  -y\n",
        "#! mamba install numpy=1.21.2 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas library\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function will download the dataset into your browser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#This function will download the dataset into your browser \n",
        "\n",
        "from pyodide.http import pyfetch\n",
        "\n",
        "async def download(url, filename):\n",
        "    response = await pyfetch(url)\n",
        "    if response.status == 200:\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(await response.bytes())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Read Data</h2>\n",
        "<p>\n",
        "We use <code>pandas.read_csv()</code> function to read the csv file. In the brackets, we put the file path along with a quotation mark so that pandas will read the file into a dataframe from that address. The file path can be either an URL or your local file address.<br>\n",
        "\n",
        "Because the data does not include headers, we can add an argument <code>headers = None</code> inside the <code>read_csv()</code> method so that pandas will not automatically set the first row as a header.<br>\n",
        "\n",
        "You can also assign the dataset to any variable you create.\n",
        "\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "you will need to download the dataset; if you are running locally, please comment out the following\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#you will need to download the dataset; if you are running locally, please comment out the following \n",
        "await download(path, \"auto.csv\")\n",
        "path=\"auto.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/DA101EN_object_storage?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# Read the online file by the URL provides above, and assign it to variable \"df\"\n",
        "\n",
        "df = pd.read_csv(path, header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After reading the dataset, we can use the <code>dataframe.head(n)</code> method to check the top n rows of the dataframe, where n is an integer. Contrary to <code>dataframe.head(n)</code>, <code>dataframe.tail(n)</code> will show you the bottom n rows of the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show the first 5 rows using dataframe.head() method\n",
        "print(\"The first 5 rows of the dataframe\") \n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>What is the purpose of data wrangling?</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data wrangling is the process of converting data from the initial format to a format that may be better for analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>What is the fuel consumption (L/100k) rate for the diesel car?</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Import data</h3>\n",
        "<p>\n",
        "You can find the \"Automobile Dataset\" from the following link: <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data</a>. \n",
        "We will be using this dataset throughout this course.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Import pandas</h4> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "you are running the lab in your  browser, so we will install the libraries using `piplite`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import piplite\n",
        "await piplite.install(['pandas'])\n",
        "await piplite.install(['matplotlib'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n",
        "#install specific version of libraries used in lab\n",
        "#! mamba install pandas==1.3.3\n",
        "#! mamba install numpy=1.21.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pylab as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function will download the dataset into your browser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#This function will download the dataset into your browser \n",
        "from pyodide.http import pyfetch\n",
        "\n",
        "async def download(url, filename):\n",
        "    response = await pyfetch(url)\n",
        "    if response.status == 200:\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(await response.bytes())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Reading the dataset from the URL and adding the related headers</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we assign the URL of the dataset to \"filename\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/corsera_da0101en_notebook_bottom?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we create a Python list <b>headers</b> containing name of headers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
        "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
        "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
        "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "you will need to download the dataset; if you are running locally, please comment out the following\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "await download(filename, \"auto.csv\")\n",
        "filename=\"auto.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the Pandas method <b>read_csv()</b> to load the data from the web address. Set the parameter  \"names\" equal to the Python list \"headers\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv(filename, names = headers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the method <b>head()</b> to display the first five rows of the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# To see what the data set looks like, we'll use the head() method.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, several question marks appeared in the dataframe; those are missing values which may hinder our further analysis.\n",
        "\n",
        "<div>So, how do we identify all those missing values and deal with them?</div> \n",
        "\n",
        "<b>How to work with missing data?</b>\n",
        "\n",
        "Steps for working with missing data:\n",
        "\n",
        "<ol>\n",
        "    <li>Identify missing data</li>\n",
        "    <li>Deal with missing data</li>\n",
        "    <li>Correct data format</li>\n",
        "</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 id=\"identify_handle_missing_values\">Identify and handle missing values</h2>\n",
        "\n",
        "<h3 id=\"identify_missing_values\">Identify missing values</h3>\n",
        "<h4>Convert \"?\" to NaN</h4>\n",
        "In the car dataset, missing data comes with the question mark \"?\".\n",
        "We replace \"?\" with NaN (Not a Number), Python's default missing value marker for reasons of computational speed and convenience. Here we use the function: \n",
        " <pre>.replace(A, B, inplace = True) </pre>\n",
        "to replace A by B.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# replace \"?\" to NaN\n",
        "df.replace(\"?\", np.nan, inplace = True)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Evaluating for Missing Data</h4>\n",
        "\n",
        "The missing values are converted by default. We use the following functions to identify these missing values. There are two methods to detect missing data:\n",
        "\n",
        "<ol>\n",
        "    <li><b>.isnull()</b></li>\n",
        "    <li><b>.notnull()</b></li>\n",
        "</ol>\n",
        "The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "missing_data = df.isnull()\n",
        "missing_data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"True\" means the value is a missing value while \"False\" means the value is not a missing value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Count missing values in each column</h4>\n",
        "<p>\n",
        "Using a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value and \"False\" means the value is present in the dataset.  In the body of the for loop the method \".value_counts()\" counts the number of \"True\" values. \n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for column in missing_data.columns.values.tolist():\n",
        "    print(column)\n",
        "    print (missing_data[column].value_counts())\n",
        "    print(\"\")    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the summary above, each column has 205 rows of data and seven of the columns containing missing data:\n",
        "\n",
        "<ol>\n",
        "    <li>\"normalized-losses\": 41 missing data</li>\n",
        "    <li>\"num-of-doors\": 2 missing data</li>\n",
        "    <li>\"bore\": 4 missing data</li>\n",
        "    <li>\"stroke\" : 4 missing data</li>\n",
        "    <li>\"horsepower\": 2 missing data</li>\n",
        "    <li>\"peak-rpm\": 2 missing data</li>\n",
        "    <li>\"price\": 4 missing data</li>\n",
        "</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 id=\"deal_missing_values\">Deal with missing data</h3>\n",
        "<b>How to deal with missing data?</b>\n",
        "\n",
        "<ol>\n",
        "    <li>Drop data<br>\n",
        "        a. Drop the whole row<br>\n",
        "        b. Drop the whole column\n",
        "    </li>\n",
        "    <li>Replace data<br>\n",
        "        a. Replace it by mean<br>\n",
        "        b. Replace it by frequency<br>\n",
        "        c. Replace it based on other functions\n",
        "    </li>\n",
        "</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Whole columns should be dropped only if most entries in the column are empty. In our dataset, none of the columns are empty enough to drop entirely.\n",
        "We have some freedom in choosing which method to replace data; however, some methods may seem more reasonable than others. We will apply each method to many different columns:\n",
        "\n",
        "<b>Replace by mean:</b>\n",
        "\n",
        "<ul>\n",
        "    <li>\"normalized-losses\": 41 missing data, replace them with mean</li>\n",
        "    <li>\"stroke\": 4 missing data, replace them with mean</li>\n",
        "    <li>\"bore\": 4 missing data, replace them with mean</li>\n",
        "    <li>\"horsepower\": 2 missing data, replace them with mean</li>\n",
        "    <li>\"peak-rpm\": 2 missing data, replace them with mean</li>\n",
        "</ul>\n",
        "\n",
        "<b>Replace by frequency:</b>\n",
        "\n",
        "<ul>\n",
        "    <li>\"num-of-doors\": 2 missing data, replace them with \"four\". \n",
        "        <ul>\n",
        "            <li>Reason: 84% sedans is four doors. Since four doors is most frequent, it is most likely to occur</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ul>\n",
        "\n",
        "<b>Drop the whole row:</b>\n",
        "\n",
        "<ul>\n",
        "    <li>\"price\": 4 missing data, simply delete the whole row\n",
        "        <ul>\n",
        "            <li>Reason: price is what we want to predict. Any data entry without price data cannot be used for prediction; therefore any row now without price data is not useful to us</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Calculate the mean value for the \"normalized-losses\" column </h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "avg_norm_loss = df[\"normalized-losses\"].astype(\"float\").mean(axis=0)\n",
        "print(\"Average of normalized-losses:\", avg_norm_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Replace \"NaN\" with mean value in \"normalized-losses\" column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Calculate the mean value for the \"bore\" column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "avg_bore=df['bore'].astype('float').mean(axis=0)\n",
        "print(\"Average of bore:\", avg_bore)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Replace \"NaN\" with the mean value in the \"bore\" column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[\"bore\"].replace(np.nan, avg_bore, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>What is the purpose of data wrangling?</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data wrangling is the process of converting data from the initial format to a format that may be better for analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>What is the fuel consumption (L/100k) rate for the diesel car?</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Import data</h3>\n",
        "<p>\n",
        "You can find the \"Automobile Dataset\" from the following link: <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data</a>. \n",
        "We will be using this dataset throughout this course.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Import pandas</h4> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "you are running the lab in your  browser, so we will install the libraries using `piplite`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import piplite\n",
        "await piplite.install(['pandas'])\n",
        "await piplite.install(['matplotlib'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n",
        "#install specific version of libraries used in lab\n",
        "#! mamba install pandas==1.3.3\n",
        "#! mamba install numpy=1.21.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pylab as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function will download the dataset into your browser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#This function will download the dataset into your browser \n",
        "from pyodide.http import pyfetch\n",
        "\n",
        "async def download(url, filename):\n",
        "    response = await pyfetch(url)\n",
        "    if response.status == 200:\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(await response.bytes())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Reading the dataset from the URL and adding the related headers</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we assign the URL of the dataset to \"filename\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/corsera_da0101en_notebook_bottom?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we create a Python list <b>headers</b> containing name of headers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
        "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
        "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
        "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "you will need to download the dataset; if you are running locally, please comment out the following\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "await download(filename, \"auto.csv\")\n",
        "filename=\"auto.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the Pandas method <b>read_csv()</b> to load the data from the web address. Set the parameter  \"names\" equal to the Python list \"headers\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv(filename, names = headers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the method <b>head()</b> to display the first five rows of the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# To see what the data set looks like, we'll use the head() method.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, several question marks appeared in the dataframe; those are missing values which may hinder our further analysis.\n",
        "\n",
        "<div>So, how do we identify all those missing values and deal with them?</div> \n",
        "\n",
        "<b>How to work with missing data?</b>\n",
        "\n",
        "Steps for working with missing data:\n",
        "\n",
        "<ol>\n",
        "    <li>Identify missing data</li>\n",
        "    <li>Deal with missing data</li>\n",
        "    <li>Correct data format</li>\n",
        "</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 id=\"identify_handle_missing_values\">Identify and handle missing values</h2>\n",
        "\n",
        "<h3 id=\"identify_missing_values\">Identify missing values</h3>\n",
        "<h4>Convert \"?\" to NaN</h4>\n",
        "In the car dataset, missing data comes with the question mark \"?\".\n",
        "We replace \"?\" with NaN (Not a Number), Python's default missing value marker for reasons of computational speed and convenience. Here we use the function: \n",
        " <pre>.replace(A, B, inplace = True) </pre>\n",
        "to replace A by B.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# replace \"?\" to NaN\n",
        "df.replace(\"?\", np.nan, inplace = True)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Evaluating for Missing Data</h4>\n",
        "\n",
        "The missing values are converted by default. We use the following functions to identify these missing values. There are two methods to detect missing data:\n",
        "\n",
        "<ol>\n",
        "    <li><b>.isnull()</b></li>\n",
        "    <li><b>.notnull()</b></li>\n",
        "</ol>\n",
        "The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "missing_data = df.isnull()\n",
        "missing_data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"True\" means the value is a missing value while \"False\" means the value is not a missing value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Count missing values in each column</h4>\n",
        "<p>\n",
        "Using a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value and \"False\" means the value is present in the dataset.  In the body of the for loop the method \".value_counts()\" counts the number of \"True\" values. \n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for column in missing_data.columns.values.tolist():\n",
        "    print(column)\n",
        "    print (missing_data[column].value_counts())\n",
        "    print(\"\")    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the summary above, each column has 205 rows of data and seven of the columns containing missing data:\n",
        "\n",
        "<ol>\n",
        "    <li>\"normalized-losses\": 41 missing data</li>\n",
        "    <li>\"num-of-doors\": 2 missing data</li>\n",
        "    <li>\"bore\": 4 missing data</li>\n",
        "    <li>\"stroke\" : 4 missing data</li>\n",
        "    <li>\"horsepower\": 2 missing data</li>\n",
        "    <li>\"peak-rpm\": 2 missing data</li>\n",
        "    <li>\"price\": 4 missing data</li>\n",
        "</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 id=\"deal_missing_values\">Deal with missing data</h3>\n",
        "<b>How to deal with missing data?</b>\n",
        "\n",
        "<ol>\n",
        "    <li>Drop data<br>\n",
        "        a. Drop the whole row<br>\n",
        "        b. Drop the whole column\n",
        "    </li>\n",
        "    <li>Replace data<br>\n",
        "        a. Replace it by mean<br>\n",
        "        b. Replace it by frequency<br>\n",
        "        c. Replace it based on other functions\n",
        "    </li>\n",
        "</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Whole columns should be dropped only if most entries in the column are empty. In our dataset, none of the columns are empty enough to drop entirely.\n",
        "We have some freedom in choosing which method to replace data; however, some methods may seem more reasonable than others. We will apply each method to many different columns:\n",
        "\n",
        "<b>Replace by mean:</b>\n",
        "\n",
        "<ul>\n",
        "    <li>\"normalized-losses\": 41 missing data, replace them with mean</li>\n",
        "    <li>\"stroke\": 4 missing data, replace them with mean</li>\n",
        "    <li>\"bore\": 4 missing data, replace them with mean</li>\n",
        "    <li>\"horsepower\": 2 missing data, replace them with mean</li>\n",
        "    <li>\"peak-rpm\": 2 missing data, replace them with mean</li>\n",
        "</ul>\n",
        "\n",
        "<b>Replace by frequency:</b>\n",
        "\n",
        "<ul>\n",
        "    <li>\"num-of-doors\": 2 missing data, replace them with \"four\". \n",
        "        <ul>\n",
        "            <li>Reason: 84% sedans is four doors. Since four doors is most frequent, it is most likely to occur</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ul>\n",
        "\n",
        "<b>Drop the whole row:</b>\n",
        "\n",
        "<ul>\n",
        "    <li>\"price\": 4 missing data, simply delete the whole row\n",
        "        <ul>\n",
        "            <li>Reason: price is what we want to predict. Any data entry without price data cannot be used for prediction; therefore any row now without price data is not useful to us</li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Calculate the mean value for the \"normalized-losses\" column </h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "avg_norm_loss = df[\"normalized-losses\"].astype(\"float\").mean(axis=0)\n",
        "print(\"Average of normalized-losses:\", avg_norm_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Replace \"NaN\" with mean value in \"normalized-losses\" column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Calculate the mean value for the \"bore\" column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "avg_bore=df['bore'].astype('float').mean(axis=0)\n",
        "print(\"Average of bore:\", avg_bore)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Replace \"NaN\" with the mean value in the \"bore\" column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[\"bore\"].replace(np.nan, avg_bore, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Calculate the mean value for the \"horsepower\" column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "avg_horsepower = df['horsepower'].astype('float').mean(axis=0)\n",
        "print(\"Average horsepower:\", avg_horsepower)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Replace \"NaN\" with the mean value in the \"horsepower\" column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df['horsepower'].replace(np.nan, avg_horsepower, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Calculate the mean value for \"peak-rpm\" column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "avg_peakrpm=df['peak-rpm'].astype('float').mean(axis=0)\n",
        "print(\"Average peak rpm:\", avg_peakrpm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Replace \"NaN\" with the mean value in the \"peak-rpm\" column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df['peak-rpm'].replace(np.nan, avg_peakrpm, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see which values are present in a particular column, we can use the \".value_counts()\" method:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df['num-of-doors'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that four doors are the most common type. We can also use the \".idxmax()\" method to calculate the most common type automatically:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df['num-of-doors'].value_counts().idxmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The replacement procedure is very similar to what we have seen previously:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#replace the missing 'num-of-doors' values by the most frequent \n",
        "df[\"num-of-doors\"].replace(np.nan, \"four\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's drop all rows that do not have price data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# simply drop whole row with NaN in \"price\" column\n",
        "df.dropna(subset=[\"price\"], axis=0, inplace=True)\n",
        "\n",
        "# reset index, because we droped two rows\n",
        "df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Good!</b> Now, we have a dataset with no missing values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 id=\"correct_data_format\">Correct data format</h3>\n",
        "<b>We are almost there!</b>\n",
        "<p>The last step in data cleaning is checking and making sure that all data is in the correct format (int, float, text or other).</p>\n",
        "\n",
        "In Pandas, we use:\n",
        "\n",
        "<p><b>.dtype()</b> to check the data type</p>\n",
        "<p><b>.astype()</b> to change the data type</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Let's list the data types for each column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>As we can see above, some columns are not of the correct data type. Numerical variables should have type 'float' or 'int', and variables with strings such as categories should have type 'object'. For example, 'bore' and 'stroke' variables are numerical values that describe the engines, so we should expect them to be of the type 'float' or 'int'; however, they are shown as type 'object'. We have to convert data types into a proper format for each column using the \"astype()\" method.</p> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Convert data types to proper format</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[[\"bore\", \"stroke\"]] = df[[\"bore\", \"stroke\"]].astype(\"float\")\n",
        "df[[\"normalized-losses\"]] = df[[\"normalized-losses\"]].astype(\"int\")\n",
        "df[[\"price\"]] = df[[\"price\"]].astype(\"float\")\n",
        "df[[\"peak-rpm\"]] = df[[\"peak-rpm\"]].astype(\"float\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Let us list the columns after the conversion</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Wonderful!</b>\n",
        "\n",
        "Now we have finally obtained the cleaned dataset with no missing values with all data in its proper format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 id=\"data_standardization\">Data Standardization</h2>\n",
        "<p>\n",
        "Data is usually collected from different agencies in different formats.\n",
        "(Data standardization is also a term for a particular type of data normalization where we subtract the mean and divide by the standard deviation.)\n",
        "</p>\n",
        "\n",
        "<b>What is standardization?</b>\n",
        "\n",
        "<p>Standardization is the process of transforming data into a common format, allowing the researcher to make the meaningful comparison.\n",
        "</p>\n",
        "\n",
        "<b>Example</b>\n",
        "\n",
        "<p>Transform mpg to L/100km:</p>\n",
        "<p>In our dataset, the fuel consumption columns \"city-mpg\" and \"highway-mpg\" are represented by mpg (miles per gallon) unit. Assume we are developing an application in a country that accepts the fuel consumption with L/100km standard.</p>\n",
        "<p>We will need to apply <b>data transformation</b> to transform mpg into L/100km.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>The formula for unit conversion is:<p>\n",
        "L/100km = 235 / mpg\n",
        "<p>We can do many mathematical operations directly in Pandas.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Convert mpg to L/100km by mathematical operation (235 divided by mpg)\n",
        "df['city-L/100km'] = 235/df[\"city-mpg\"]\n",
        "\n",
        "# check your transformed data \n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 id=\"data_normalization\">Data Normalization</h2>\n",
        "\n",
        "<b>Why normalization?</b>\n",
        "\n",
        "<p>Normalization is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, scaling the variable so the variance is 1, or scaling the variable so the variable values range from 0 to 1.\n",
        "</p>\n",
        "\n",
        "<b>Example</b>\n",
        "\n",
        "<p>To demonstrate normalization, let's say we want to scale the columns \"length\", \"width\" and \"height\".</p>\n",
        "<p><b>Target:</b> would like to normalize those variables so their value ranges from 0 to 1</p>\n",
        "<p><b>Approach:</b> replace original value by (original value)/(maximum value)</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# replace (original value) by (original value)/(maximum value)\n",
        "df['length'] = df['length']/df['length'].max()\n",
        "df['width'] = df['width']/df['width'].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we can see we've normalized \"length\", \"width\" and \"height\" in the range of \\[0,1].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 id=\"binning\">Binning</h2>\n",
        "<b>Why binning?</b>\n",
        "<p>\n",
        "    Binning is a process of transforming continuous numerical variables into discrete categorical 'bins' for grouped analysis.\n",
        "</p>\n",
        "\n",
        "<b>Example: </b>\n",
        "\n",
        "<p>In our dataset, \"horsepower\" is a real valued variable ranging from 48 to 288 and it has 59 unique values. What if we only care about the price difference between cars with high horsepower, medium horsepower, and little horsepower (3 types)? Can we rearrange them into three â€˜bins' to simplify analysis? </p>\n",
        "\n",
        "<p>We will use the pandas method 'cut' to segment the 'horsepower' column into 3 bins.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Example of Binning Data In Pandas</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert data to correct format:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[\"horsepower\"]=df[\"horsepower\"].astype(int, copy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the histogram of horsepower to see what the distribution of horsepower looks like.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as plt\n",
        "from matplotlib import pyplot\n",
        "plt.pyplot.hist(df[\"horsepower\"])\n",
        "\n",
        "# set x/y labels and plot title\n",
        "plt.pyplot.xlabel(\"horsepower\")\n",
        "plt.pyplot.ylabel(\"count\")\n",
        "plt.pyplot.title(\"horsepower bins\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>We would like 3 bins of equal size bandwidth so we use numpy's <code>linspace(start_value, end_value, numbers_generated</code> function.</p>\n",
        "<p>Since we want to include the minimum value of horsepower, we want to set start_value = min(df[\"horsepower\"]).</p>\n",
        "<p>Since we want to include the maximum value of horsepower, we want to set end_value = max(df[\"horsepower\"]).</p>\n",
        "<p>Since we are building 3 bins of equal length, there should be 4 dividers, so numbers_generated = 4.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We build a bin array with a minimum value to a maximum value by using the bandwidth calculated above. The values will determine when one bin ends and another begins.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "bins = np.linspace(min(df[\"horsepower\"]), max(df[\"horsepower\"]), 4)\n",
        "bins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set group  names:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "group_names = ['Low', 'Medium', 'High']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We apply the function \"cut\" to determine what each value of `df['horsepower']` belongs to.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels=group_names, include_lowest=True )\n",
        "df[['horsepower','horsepower-binned']].head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see the number of vehicles in each bin:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[\"horsepower-binned\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the distribution of each bin:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as plt\n",
        "from matplotlib import pyplot\n",
        "pyplot.bar(group_names, df[\"horsepower-binned\"].value_counts())\n",
        "\n",
        "# set x/y labels and plot title\n",
        "plt.pyplot.xlabel(\"horsepower\")\n",
        "plt.pyplot.ylabel(\"count\")\n",
        "plt.pyplot.title(\"horsepower bins\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>\n",
        "    Look at the dataframe above carefully. You will find that the last column provides the bins for \"horsepower\" based on 3 categories (\"Low\", \"Medium\" and \"High\"). \n",
        "</p>\n",
        "<p>\n",
        "    We successfully narrowed down the intervals from 59 to 3!\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Bins Visualization</h3>\n",
        "Normally, a histogram is used to visualize the distribution of bins we created above. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as plt\n",
        "from matplotlib import pyplot\n",
        "\n",
        "\n",
        "# draw historgram of attribute \"horsepower\" with bins = 3\n",
        "plt.pyplot.hist(df[\"horsepower\"], bins = 3)\n",
        "\n",
        "# set x/y labels and plot title\n",
        "plt.pyplot.xlabel(\"horsepower\")\n",
        "plt.pyplot.ylabel(\"count\")\n",
        "plt.pyplot.title(\"horsepower bins\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The plot above shows the binning result for the attribute \"horsepower\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 id=\"indicator\">Indicator Variable (or Dummy Variable)</h2>\n",
        "<b>What is an indicator variable?</b>\n",
        "<p>\n",
        "    An indicator variable (or dummy variable) is a numerical variable used to label categories. They are called 'dummies' because the numbers themselves don't have inherent meaning. \n",
        "</p>\n",
        "\n",
        "<b>Why we use indicator variables?</b>\n",
        "\n",
        "<p>\n",
        "    We use indicator variables so we can use categorical variables for regression analysis in the later modules.\n",
        "</p>\n",
        "<b>Example</b>\n",
        "<p>\n",
        "    We see the column \"fuel-type\" has two unique values: \"gas\" or \"diesel\". Regression doesn't understand words, only numbers. To use this attribute in regression analysis, we convert \"fuel-type\" to indicator variables.\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "    We will use pandas' method 'get_dummies' to assign numerical values to different categories of fuel type. \n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the indicator variables and assign it to data frame \"dummy_variable\\_1\":\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dummy_variable_1 = pd.get_dummies(df[\"fuel-type\"])\n",
        "dummy_variable_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change the column names for clarity:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dummy_variable_1.rename(columns={'gas':'fuel-type-gas', 'diesel':'fuel-type-diesel'}, inplace=True)\n",
        "dummy_variable_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the dataframe, column 'fuel-type' has values for 'gas' and 'diesel' as 0s and 1s now.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# merge data frame \"df\" and \"dummy_variable_1\" \n",
        "df = pd.concat([df, dummy_variable_1], axis=1)\n",
        "\n",
        "# drop original column \"fuel-type\" from \"df\"\n",
        "df.drop(\"fuel-type\", axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The last two columns are now the indicator variable representation of the fuel-type variable. They're all 0s and 1s now.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>1. Linear Regression and Multiple Linear Regression</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Linear Regression</h4>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>One example of a Data  Model that we will be using is:</p>\n",
        "<b>Simple Linear Regression</b>\n",
        "\n",
        "<br>\n",
        "<p>Simple Linear Regression is a method to help us understand the relationship between two variables:</p>\n",
        "<ul>\n",
        "    <li>The predictor/independent variable (X)</li>\n",
        "    <li>The response/dependent variable (that we want to predict)(Y)</li>\n",
        "</ul>\n",
        "\n",
        "<p>The result of Linear Regression is a <b>linear function</b> that predicts the response (dependent) variable as a function of the predictor (independent) variable.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "Y: Response \\ Variable\\\\\\\\\\\\\\\\\\\\\n",
        "X: Predictor \\ Variables\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Linear Function</b>\n",
        "$$\n",
        "Yhat = a + b  X\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<ul>\n",
        "    <li>a refers to the <b>intercept</b> of the regression line, in other words: the value of Y when X is 0</li>\n",
        "    <li>b refers to the <b>slope</b> of the regression line, in other words: the value with which Y changes when X increases by 1 unit</li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Let's load the modules for linear regression:</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>Create the linear regression object:</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "lm = LinearRegression()\n",
        "lm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>How could \"highway-mpg\" help us predict car price?</h4>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this example, we want to look at how highway-mpg can help us predict car price.\n",
        "Using simple linear regression, we will create a linear function with \"highway-mpg\" as the predictor variable and the \"price\" as the response variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X = df[['highway-mpg']]\n",
        "Y = df['price']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the linear model using highway-mpg:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "lm.fit(X,Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can output a prediction:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Yhat=lm.predict(X)\n",
        "Yhat[0:5]   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>What is the value of the intercept (a)?</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "lm.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h4>What is the value of the slope (b)?</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "lm.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>What is the final estimated linear model we get?</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we saw above, we should get a final linear model with the structure:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$$\n",
        "Yhat = a + b  X\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plugging in the actual values we get:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Price</b> = 38423.31 - 821.73 x <b>highway-mpg</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>2. Model Evaluation Using Visualization</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we've developed some models, how do we evaluate our models and choose the best one? One way to do this is by using a visualization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the visualization package, seaborn:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# import the visualization package: seaborn\n",
        "import seaborn as sns\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Regression Plot</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>When it comes to simple linear regression, an excellent way to visualize the fit of our model is by using <b>regression plots</b>.</p>\n",
        "\n",
        "<p>This plot will show a combination of a scattered data points (a <b>scatterplot</b>), as well as the fitted <b>linear regression</b> line going through the data. This will give us a reasonable estimate of the relationship between the two variables, the strength of the correlation, as well as the direction (positive or negative correlation).</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's visualize **highway-mpg** as potential predictor variable of price:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "width = 12\n",
        "height = 10\n",
        "plt.figure(figsize=(width, height))\n",
        "sns.regplot(x=\"highway-mpg\", y=\"price\", data=df)\n",
        "plt.ylim(0,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>We can see from this plot that price is negatively correlated to highway-mpg since the regression slope is negative.\n",
        "\n",
        "One thing to keep in mind when looking at a regression plot is to pay attention to how scattered the data points are around the regression line. This will give you a good indication of the variance of the data and whether a linear model would be the best fit or not. If the data is too far off from the line, this linear model might not be the best model for this data.\n",
        "\n",
        "Let's compare this plot to the regression plot of \"peak-rpm\".</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(width, height))\n",
        "sns.regplot(x=\"peak-rpm\", y=\"price\", data=df)\n",
        "plt.ylim(0,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>Comparing the regression plot of \"peak-rpm\" and \"highway-mpg\", we see that the points for \"highway-mpg\" are much closer to the generated line and, on average, decrease. The points for \"peak-rpm\" have more spread around the predicted line and it is much harder to determine if the points are decreasing or increasing as the \"peak-rpm\" increases.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>Comparing the regression plot of \"peak-rpm\" and \"highway-mpg\", we see that the points for \"highway-mpg\" are much closer to the generated line and, on average, decrease. The points for \"peak-rpm\" have more spread around the predicted line and it is much harder to determine if the points are decreasing or increasing as the \"peak-rpm\" increases.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
        "<h1>Question #3:</h1>\n",
        "<b>Given the regression plots above, is \"peak-rpm\" or \"highway-mpg\" more strongly correlated with \"price\"? Use the method  \".corr()\" to verify your answer.</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Residual Plot</h3>\n",
        "\n",
        "<p>A good way to visualize the variance of the data is to use a residual plot.</p>\n",
        "\n",
        "<p>What is a <b>residual</b>?</p>\n",
        "\n",
        "<p>The difference between the observed value (y) and the predicted value (Yhat) is called the residual (e). When we look at a regression plot, the residual is the distance from the data point to the fitted regression line.</p>\n",
        "\n",
        "<p>So what is a <b>residual plot</b>?</p>\n",
        "\n",
        "<p>A residual plot is a graph that shows the residuals on the vertical y-axis and the independent variable on the horizontal x-axis.</p>\n",
        "\n",
        "<p>What do we pay attention to when looking at a residual plot?</p>\n",
        "\n",
        "<p>We look at the spread of the residuals:</p>\n",
        "\n",
        "<p>- If the points in a residual plot are <b>randomly spread out around the x-axis</b>, then a <b>linear model is appropriate</b> for the data.\n",
        "\n",
        "Why is that? Randomly spread out residuals means that the variance is constant, and thus the linear model is a good fit for this data.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "width = 12\n",
        "height = 10\n",
        "plt.figure(figsize=(width, height))\n",
        "sns.residplot(x=df['highway-mpg'],y=df['price'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<i>What is this plot telling us?</i>\n",
        "\n",
        "<p>We can see from this residual plot that the residuals are not randomly spread around the x-axis, leading us to believe that maybe a non-linear model is more appropriate for this data.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Multiple Linear Regression</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>How do we visualize a model for Multiple Linear Regression? This gets a bit more complicated because you can't visualize it with regression or residual plot.</p>\n",
        "\n",
        "<p>One way to look at the fit of the model is by looking at the <b>distribution plot</b>. We can look at the distribution of the fitted values that result from the model and compare it to the distribution of the actual values.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's make a prediction:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Y_hat = lm.predict(Z)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(width, height))\n",
        "\n",
        "\n",
        "ax1 = sns.distplot(df['price'], hist=False, color=\"r\", label=\"Actual Value\")\n",
        "sns.distplot(Y_hat, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
        "\n",
        "\n",
        "plt.title('Actual vs Fitted Values for Price')\n",
        "plt.xlabel('Price (in dollars)')\n",
        "plt.ylabel('Proportion of Cars')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>We can see that the fitted values are reasonably close to the actual values since the two distributions overlap a bit. However, there is definitely some room for improvement.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>3. Polynomial Regression and Pipelines</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p><b>Polynomial regression</b> is a particular case of the general linear regression model or multiple linear regression models.</p> \n",
        "<p>We get non-linear relationships by squaring or setting higher-order terms of the predictor variables.</p>\n",
        "\n",
        "<p>There are different orders of polynomial regression:</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><b>Quadratic - 2nd Order</b></center>\n",
        "$$\n",
        "Yhat = a + b_1 X +b_2 X^2 \n",
        "$$\n",
        "\n",
        "<center><b>Cubic - 3rd Order</b></center>\n",
        "$$\n",
        "Yhat = a + b_1 X +b_2 X^2 +b_3 X^3\\\\\\\\\\\\\\\\\\\\\n",
        "$$\n",
        "\n",
        "<center><b>Higher-Order</b>:</center>\n",
        "$$\n",
        "Y = a + b_1 X +b_2 X^2 +b_3 X^3 ....\\\\\\\\\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>We saw earlier that a linear model did not provide the best fit while using \"highway-mpg\" as the predictor variable. Let's see if we can try fitting a polynomial model to the data instead.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>We will use the following function to plot the data:</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def PlotPolly(model, independent_variable, dependent_variabble, Name):\n",
        "    x_new = np.linspace(15, 55, 100)\n",
        "    y_new = model(x_new)\n",
        "\n",
        "    plt.plot(independent_variable, dependent_variabble, '.', x_new, y_new, '-')\n",
        "    plt.title('Polynomial Fit with Matplotlib for Price ~ Length')\n",
        "    ax = plt.gca()\n",
        "    ax.set_facecolor((0.898, 0.898, 0.898))\n",
        "    fig = plt.gcf()\n",
        "    plt.xlabel(Name)\n",
        "    plt.ylabel('Price of Cars')\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's get the variables:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "x = df['highway-mpg']\n",
        "y = df['price']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's fit the polynomial using the function <b>polyfit</b>, then use the function <b>poly1d</b> to display the polynomial function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Here we use a polynomial of the 3rd order (cubic) \n",
        "f = np.polyfit(x, y, 3)\n",
        "p = np.poly1d(f)\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the function:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "PlotPolly(p, x, y, 'highway-mpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "np.polyfit(x, y, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>We can already see from plotting that this polynomial model performs better than the linear model. This is because the generated polynomial function  \"hits\" more of the data points.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>4. Measures for In-Sample Evaluation</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>When evaluating our models, not only do we want to visualize the results, but we also want a quantitative measure to determine how accurate the model is.</p>\n",
        "\n",
        "<p>Two very important measures that are often used in Statistics to determine the accuracy of a model are:</p>\n",
        "<ul>\n",
        "    <li><b>R^2 / R-squared</b></li>\n",
        "    <li><b>Mean Squared Error (MSE)</b></li>\n",
        "</ul>\n",
        "\n",
        "<b>R-squared</b>\n",
        "\n",
        "<p>R squared, also known as the coefficient of determination, is a measure to indicate how close the data is to the fitted regression line.</p>\n",
        "\n",
        "<p>The value of the R-squared is the percentage of variation of the response variable (y) that is explained by a linear model.</p>\n",
        "\n",
        "<b>Mean Squared Error (MSE)</b>\n",
        "\n",
        "<p>The Mean Squared Error measures the average of the squares of errors. That is, the difference between actual value (y) and the estimated value (Å·).</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Model 1: Simple Linear Regression</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's calculate the R^2:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#highway_mpg_fit\n",
        "lm.fit(X, Y)\n",
        "# Find the R^2\n",
        "print('The R-square is: ', lm.score(X, Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can say that \\~49.659% of the variation of the price is explained by this simple linear model \"horsepower_fit\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's calculate the MSE:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can predict the output i.e., \"yhat\" using the predict method, where X is the input variable:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Yhat=lm.predict(X)\n",
        "print('The output of the first four predicted value is: ', Yhat[0:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's import the function <b>mean_squared_error</b> from the module <b>metrics</b>:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compare the predicted results with the actual results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mse = mean_squared_error(df['price'], Yhat)\n",
        "print('The mean square error of price and predicted value is: ', mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Model 2: Multiple Linear Regression</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's calculate the R^2:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# fit the model \n",
        "lm.fit(Z, df['price'])\n",
        "# Find the R^2\n",
        "print('The R-square is: ', lm.score(Z, df['price']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can say that \\~80.896 % of the variation of price is explained by this multiple linear regression \"multi_fit\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's calculate the MSE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We produce a prediction:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Y_predict_multifit = lm.predict(Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compare the predicted results with the actual results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print('The mean square error of price and predicted value using multifit is: ', \\\n",
        "      mean_squared_error(df['price'], Y_predict_multifit))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Model 3: Polynomial Fit</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's calculate the R^2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Letâ€™s import the function <b>r2\\_score</b> from the module <b>metrics</b> as we are using a different function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We apply the function to get the value of R^2:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "r_squared = r2_score(y, p(x))\n",
        "print('The R-square value is: ', r_squared)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can say that \\~67.419 % of the variation of price is explained by this polynomial fit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>MSE</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also calculate the MSE:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mean_squared_error(df['price'], p(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>5. Prediction and Decision Making</h2>\n",
        "<h3>Prediction</h3>\n",
        "\n",
        "<p>In the previous section, we trained the model using the method <b>fit</b>. Now we will use the method <b>predict</b> to produce a prediction. Lets import <b>pyplot</b> for plotting; we will also be using some functions from numpy.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a new input:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "new_input=np.arange(1, 100, 1).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "lm.fit(X, Y)\n",
        "lm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Produce a prediction:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "yhat=lm.predict(new_input)\n",
        "yhat[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.plot(new_input, yhat)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Decision Making: Determining a Good Model Fit</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>Now that we have visualized the different models, and generated the R-squared and MSE values for the fits, how do we determine a good model fit?\n",
        "<ul>\n",
        "    <li><i>What is a good R-squared value?</i></li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<p>When comparing models, <b>the model with the higher R-squared value is a better fit</b> for the data.\n",
        "<ul>\n",
        "    <li><i>What is a good MSE?</i></li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<p>When comparing models, <b>the model with the smallest MSE value is a better fit</b> for the data.</p>\n",
        "\n",
        "<h4>Let's take a look at the values for the different models.</h4>\n",
        "<p>Simple Linear Regression: Using Highway-mpg as a Predictor Variable of Price.\n",
        "<ul>\n",
        "    <li>R-squared: 0.49659118843391759</li>\n",
        "    <li>MSE: 3.16 x10^7</li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<p>Multiple Linear Regression: Using Horsepower, Curb-weight, Engine-size, and Highway-mpg as Predictor Variables of Price.\n",
        "<ul>\n",
        "    <li>R-squared: 0.80896354913783497</li>\n",
        "    <li>MSE: 1.2 x10^7</li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<p>Polynomial Fit: Using Highway-mpg as a Predictor Variable of Price.\n",
        "<ul>\n",
        "    <li>R-squared: 0.6741946663906514</li>\n",
        "    <li>MSE: 2.05 x 10^7</li>\n",
        "</ul>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Simple Linear Regression Model (SLR) vs Multiple Linear Regression Model (MLR)</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p>Usually, the more variables you have, the better your model is at predicting, but this is not always true. Sometimes you may not have enough data, you may run into numerical problems, or many of the variables may not be useful and even act as noise. As a result, you should always check the MSE and R^2.</p>\n",
        "\n",
        "<p>In order to compare the results of the MLR vs SLR models, we look at a combination of both the R-squared and MSE to make the best conclusion about the fit of the model.\n",
        "<ul>\n",
        "    <li><b>MSE</b>: The MSE of SLR is  3.16x10^7  while MLR has an MSE of 1.2 x10^7.  The MSE of MLR is much smaller.</li>\n",
        "    <li><b>R-squared</b>: In this case, we can also see that there is a big difference between the R-squared of the SLR and the R-squared of the MLR. The R-squared for the SLR (~0.497) is very small compared to the R-squared for the MLR (~0.809).</li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "This R-squared in combination with the MSE show that MLR seems like the better model fit in this case compared to SLR.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Simple Linear Model (SLR) vs. Polynomial Fit</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<ul>\n",
        "    <li><b>MSE</b>: We can see that Polynomial Fit brought down the MSE, since this MSE is smaller than the one from the SLR.</li> \n",
        "    <li><b>R-squared</b>: The R-squared for the Polynomial Fit is larger than the R-squared for the SLR, so the Polynomial Fit also brought up the R-squared quite a bit.</li>\n",
        "</ul>\n",
        "<p>Since the Polynomial Fit resulted in a lower MSE and a higher R-squared, we can conclude that this was a better fit model than the simple linear regression for predicting \"price\" with \"highway-mpg\" as a predictor variable.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3>Multiple Linear Regression (MLR) vs. Polynomial Fit</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<ul>\n",
        "    <li><b>MSE</b>: The MSE for the MLR is smaller than the MSE for the Polynomial Fit.</li>\n",
        "    <li><b>R-squared</b>: The R-squared for the MLR is also much larger than for the Polynomial Fit.</li>\n",
        "</ul>\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "assignment01.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
